<!-- <div align="center">
<h1>
  Zhigong
</h1>
</div> -->

<div align="center"><img src="misc/logo.png" width="550"/></div>


<p align="center">
  ğŸ‘¨â€ğŸ’» <a href="https://github.com/ciictec/Zhigong1.6B" target="_blank">Github</a> â€¢ ğŸ¤— <a href="https://huggingface.co/ciictec" target="_blank">Hugging Face</a>
</p>


# é¡¹ç›®ä»‹ç»
Zhigong-1.6Bæ˜¯å·¥ä¸šé¢†åŸŸè½»é‡åŒ–å¼€æºå¤§æ¨¡å‹ï¼Œé‡‡ç”¨3.2Tçš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒã€‚
- è¯¥åº•åº§äº§å“é¢å‘è¾¹ç¼˜è®¡ç®—å’Œæ™ºèƒ½ç»ˆç«¯ï¼Œ1.6Bå‚æ•°å®ç°äº†æ¨¡å‹å‚æ•°çš„è½»é‡çº§åŒ–ã€‚è¯¥åº•åº§äº§å“ï¼Œæä¾›é«˜åº¦çµæ´»çš„é¢„è®­ç»ƒæ¡†æ¶ï¼Œå¯ä»¥å°†èƒ½åŠ›æ‰©å±•è‡³å·¥ä¸šè®¾å¤‡ã€æ™ºèƒ½è®¾å¤‡å’Œå·¥ä¸šäº§å“ï¼Œä¸ºå·¥ä¸šåº”ç”¨åœºæ™¯æä¾›æ›´é«˜æ•ˆçš„è®¡ç®—æ€§èƒ½ã€‚
- è¯¥åº•åº§äº§å“å®ç°äº†å¯¹æ±‰è¯­ã€è‹±è¯­ã€æ³•è¯­ã€ä¿„è¯­ã€è¥¿ç­ç‰™è¯­ã€æŸ¬åŸ”å¯¨è¯­ã€æ·å…‹è¯­ã€åŒˆç‰™åˆ©è¯­ã€å°åº¦å°¼è¥¿äºšè¯­ã€å“ˆè¨å…‹è¯­ã€è€æŒè¯­ã€è’™å¤è¯­ã€æ³¢å…°è¯­ã€å¡å°”ç»´äºšè¯­ã€åœŸè€³å…¶è¯­ã€è¶Šå—è¯­ã€æ—¥è¯­å’ŒéŸ©è¯­ç­‰18ç§è¯­è¨€æ–‡å­—è¯­è¨€å¢å¼ºæŠ€æœ¯ã€‚

# æ›´æ–°ä¿¡æ¯
* 2023.12.28 æ™ºå·¥å¼€æº1.6Bå·¥ä¸šå¤§æ¨¡å‹å·²å¼€æ”¾ã€‚åœ°å€ï¼š[huggingface](https://huggingface.co/ciictec)

# ç›®å½•

- [ä¸‹è½½åœ°å€](#ä¸‹è½½åœ°å€)
- [æ¨¡å‹ä»‹ç»](#æ¨¡å‹ä»‹ç»)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ¨¡å‹æ ·ä¾‹å±•ç¤º](#æ¨¡å‹æ ·ä¾‹å±•ç¤º)
<!-- - [å£°æ˜å’Œåè®®](#å£°æ˜å’Œåè®®) -->
<!-- - [å¼•ç”¨å’Œè”ç³»æˆ‘ä»¬](#å¼•ç”¨å’Œè”ç³»æˆ‘ä»¬) -->


# ä¸‹è½½åœ°å€
## æ¨¡å‹ä¸‹è½½
| æ¨¡å‹ | ä¸‹è½½åœ°å€ |
| --------- | ------ | 
| Zhigong-1.6B-Base     |  ğŸ¤—[Zhigong-1.6B-Base](https://huggingface.co/ciictec/Zhigong-1.6B-Base)|
| Zhigong-1.6B-Chat     |  ğŸ¤—[Zhigong-1.6B-Chat](https://huggingface.co/ciictec/Zhigong-1.6B-Chat)|



# æ¨¡å‹ä»‹ç»

## è®­ç»ƒæ•°æ®
æˆ‘ä»¬é’ˆå¯¹å·¥ä¸šåœºæ™¯é‡æ–°æ„å»ºäº†æ•°æ®ç­›é€‰æµç¨‹ï¼ŒZhigong-1.6B-Baseæ¨¡å‹æ˜¯åœ¨æ¸…æ´—åçš„3.2Té«˜è´¨é‡ä¸­ã€è‹±ã€ä»£ç æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¤§å¹…åº¦æå‡äº†å›¾ä¹¦ã€è®ºæ–‡ã€é¢†åŸŸæ•°æ®æ¯”ä¾‹ã€‚

|  | ç±»ç›®     | ç™¾åˆ†æ¯”    |
| ---------------------------- | ------ | ------ |
| è‹±æ–‡                           | ç½‘é¡µæ•°æ®   | 36.20% |
|                              | ä¹¦ç±æ•°æ®   | 8.70%  |
|                              | å·¥ä¸šé¢†åŸŸæ•°æ® | 2.60%  |
|                              | å­¦æœ¯è®ºæ–‡   | 2.50%  |
|                              | ç™¾ç§‘     | 0.50%  |
|                              | å…¶ä»–     | 1.90%  |
| ä¸­æ–‡                           | ç½‘é¡µæ•°æ®   | 25.20% |
|                              | ä¹¦ç±æ•°æ®   | 6.50%  |
|                              | å·¥ä¸šé¢†åŸŸæ•°æ® | 2.50%  |
|                              | ç™¾ç§‘å…¨ä¹¦   | 0.80%  |
|                              | å…¶ä»–     | 1.60%  |
| å…¶ä»–è¯­è¨€                         | ç™¾ç§‘     | 2.40%  |
|                              | å›¾ä¹¦     | 2.60%  |
| ä»£ç                            | Github | 6.00%  |

## æ¨¡å‹ç»“æ„
æ•´ä½“æ¨¡å‹åŸºäºæ ‡å‡†çš„ Transformer ç»“æ„ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å’Œ LLaMA-2ç›¸åŒçš„æ¨¡å‹è®¾è®¡ã€‚å±‚æ•°ä¸º24å±‚ï¼ŒHidden Dim ä¸º2048ï¼Œè®­ç»ƒåºåˆ—é•¿åº¦ä¸º2048ã€‚
| æ¨¡å‹ç»“æ„              | **Zhigong-1.6B** |
| ----------------- | ------------ |
| è¯è¡¨å¤§å°              | 103368       |
| Hidden Dim        | 2048         |
| Intermediate Size | 5632         |
| Head Dim          | 128          |
| Attentionå¤´æ•°       | 16           |
| å±‚æ•°                | 24           |
| è®­ç»ƒåºåˆ—é•¿åº¦            | 2048         |
| ä½ç½®ç¼–ç               | RoPE      |

## åˆ†è¯å™¨ 
æˆ‘ä»¬ä½¿ç”¨Byte-Pair Encodingï¼ˆBPEï¼‰å¯¹æ•°æ®è¿›è¡Œåˆ†è¯ã€‚Zhigong-1.6Bèšç„¦â€œä¸€å¸¦ä¸€è·¯â€å›½é™…åˆä½œé«˜å³°è®ºå›ï¼Œæ”¯æŒæ±‰è¯­ã€è‹±è¯­ã€æ³•è¯­ã€ä¿„è¯­ã€è¥¿ç­ç‰™è¯­ã€æŸ¬åŸ”å¯¨è¯­ã€æ·å…‹è¯­ã€åŒˆç‰™åˆ©è¯­ã€å°åº¦å°¼è¥¿äºšè¯­ã€å“ˆè¨å…‹è¯­ã€è€æŒè¯­ã€è’™å¤è¯­ã€æ³¢å…°è¯­ã€å¡å°”ç»´äºšè¯­ã€åœŸè€³å…¶è¯­ã€è¶Šå—è¯­ã€æ—¥è¯­å’ŒéŸ©è¯­ã€‚å¹¶ä¸”é’ˆå¯¹é™¤è‹±è¯­å¤–çš„â€œä¸€å¸¦ä¸€è·¯â€å›½å®¶è¯­è¨€é¢å¤–å¼•å…¥1ä¸‡ä¸ªè¯å…ƒã€‚


# æ¨¡å‹è¯„ä¼°
## MMLUè¯„ä¼°
| Model                 | MMLU  |
| ------------------------------------------------- | ----- |
| Gpt-neo-1.3B                                      | 24.51 |
| Opt-1.3b                                          | 24.88 |
| TinyLlama-1.1B-intermediate-step-1195k-token-2.5T | 25.92 |
| Pythia-1b                                         | 26.21 |
| Bloom-3b                                          | 26.3  |
| Bloom-1b1                                         | 26.6  |
| Bloomz-1b1                                        | 27.05 |
| Bloom-1b7                                         | 27.59 |
| **Zhigong-1.6B**                                       | **28.01** |

# å¿«é€Ÿå¼€å§‹
æˆ‘ä»¬å°†æ¨¡å‹å‚æ•°ã€é…ç½®æ–‡ä»¶ã€tokenizerç­‰åœ¨Hugging Faceä¸Šè¿›è¡Œäº†å¼€æºã€‚

## ä¾èµ–å®‰è£…
- Python 3.8åŠä»¥ä¸Šç‰ˆæœ¬
- Pytorch 1.13åŠä»¥ä¸Šç‰ˆæœ¬
- CUDAå»ºè®®ä½¿ç”¨11.4ä»¥ä¸Šç‰ˆæœ¬

è¿è¡Œä¸‹é¢çš„è„šæœ¬è¿›è¡ŒPythonä¾èµ–å®‰è£…ã€‚
```shell
pip install -r requirements.txt 
```

## Baseæ¨¡å‹æ¨ç†
```
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.generation import GenerationConfig
import torch

model_path = "ciictec/Zhigong-1.6B-Base"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False, add_bos_token=False)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto", trust_remote_code=True).eval()

inputs = tokenizer('é»„æ²³å‘æºäºé’è—é«˜åŸ', return_tensors='pt').to(model.device)
response = model.generate(inputs.input_ids, max_length=128)
print(tokenizer.decode(response.cpu()[0], skip_special_tokens=True))
"""
é»„æ²³å‘æºäºé’è—é«˜åŸçš„ä¸–ç•Œå±‹è„Šï¼Œæ˜¯ä¸­å›½çš„â€œç¬¬äºŒæ¡å¤§æ²³â€ã€‚å®ƒæµç»9ä¸ªçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚ï¼ŒæµåŸŸé¢ç§¯çº¦960ä¸‡å¹³æ–¹åƒç±³ï¼Œå å…¨å›½é¢ç§¯çš„71%ï¼Œä¸ºä¸­å›½çš„â€œæ°´å¡”â€ã€‚
å®ƒä¹Ÿæ˜¯ä¸–ç•Œä¸Šæ°´é‡æœ€å¤§ã€æµåŸŸé¢ç§¯æœ€å¹¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæ°´èµ„æºæœ€ä¸°å¯Œçš„æ²³æµä¹‹ä¸€ã€‚
å®ƒä¹Ÿæ˜¯ä¸­å›½çš„â€œç”Ÿå‘½ä¹‹æ²³â€ï¼Œè¢«èª‰ä¸ºâ€œä¸­åæ°´å¡”â€ã€‚
"""
```

## Chatæ¨¡å‹æ¨ç†
```
import os
import re
from typing import Tuple, List, Dict
import torch
from loguru import logger
from transformers import AutoTokenizer, LlamaForCausalLM

model_name = "Assistant"
human_prompt = "<|Human|>"
assistant_prompt = f"<|{model_name}|>"

class ModelChat(LlamaForCausalLM):
    def __init__(self, config, tokenizer):
        super().__init__(config)
        self.tokenizer = tokenizer
        self.tokenizer.add_special_tokens({"additional_special_tokens": [human_prompt, assistant_prompt]})
        self.history = []

    def process_response(self, response):
        response = response.strip()
        punkts = [
            [",", "ï¼Œ"],
            ["!", "ï¼"],
            [":", "ï¼š"],
            [";", "ï¼›"],
            ["\?", "ï¼Ÿ"],
        ]
        for item in punkts:
            response = re.sub(r"([\u4e00-\u9fff])%s" % item[0], r"\1%s" % item[1], response)
            response = re.sub(r"%s([\u4e00-\u9fff])" % item[0], r"%s\1" % item[1], response)
        response = response.replace(self.tokenizer.eos_token, "").replace(self.tokenizer.bos_token, "").strip()
        return response

    @torch.no_grad()
    def chat(self, query: str, history: List[Tuple[str, str]] = None, max_length: int = 2048, num_beams=1,
             do_sample=True, top_p=0.7, top_k=50, temperature=0.8, repetition_penalty=1.0, **kwargs):
        if history is None:
            history = []
        gen_kwargs = {"max_length": max_length, "num_beams": num_beams, "do_sample": do_sample, "top_p": top_p,
                      "top_k": top_k, "temperature": temperature, "repetition_penalty": repetition_penalty,
                      "bos_token_id": self.tokenizer.bos_token_id, "eos_token_id": self.tokenizer.eos_token_id, **kwargs}
        history_prompt = ""
        for turn in history:
            history_prompt += turn[0] + turn[1]
        wrap_query = human_prompt + str(query)
        prompt = history_prompt + wrap_query + assistant_prompt 
        inputs = self.tokenizer([prompt], return_tensors="pt")
        inputs = inputs.to(self.device)
        outputs = self.generate(**inputs, **gen_kwargs)
        outputs = outputs.tolist()[0][len(inputs["input_ids"][0]):]
        response = self.tokenizer.decode(outputs)
        response = self.process_response(response)
        history.append([wrap_query, assistant_prompt + response + self.tokenizer.eos_token])
        
        return response, history

if __name__ == '__main__':
    model_path = "ciictec/Zhigong-1.6B-Chat"
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False, add_bos_token=False)
    model = ModelChat.from_pretrained(model_path, tokenizer=tokenizer, device_map="auto").half()

    q = "<<æ¡ƒèŠ±æºè®°>>é‡Œé™¶æ¸Šæ˜è¡¨è¾¾äº†ä»€ä¹ˆæ ·çš„æ€æƒ³"
    response, history = model.chat(query=q, max_length=2048,history=None)
    print(response)

    """ç”Ÿæˆç»“æœï¼š
    é€ƒé¿ç°å®ã€‚é™¶æ¸Šæ˜åœ¨ã€Šæ¡ƒèŠ±æºè®°ã€‹ä¸­ï¼Œä»¥â€œæ¡ƒèŠ±æºâ€ä¸ºè±¡å¾ï¼Œæç»˜äº†ä¸€ä¸ªä¸ç°å®ç¤¾ä¼šæˆªç„¶ä¸åŒçš„ç†æƒ³ç¤¾ä¼šï¼Œåœ¨è¿™ä¸ªç¤¾ä¼šä¸­ï¼Œäººä»¬è¿‡ç€å¿«ä¹ã€å®‰å®çš„ç”Ÿæ´»ï¼Œä¸è‡ªç„¶å’Œè°ç›¸å¤„ï¼Œäººä»¬ä¸å…³å¿ƒæ”¿æ²»ï¼Œä¸è¿½æ±‚ååˆ©ï¼Œè¿‡ç€ä¸ä¸–æ— äº‰çš„ç”Ÿæ´»ã€‚é™¶æ¸Šæ˜åœ¨è¿™é‡Œæ‰€è¡¨è¾¾çš„æ€æƒ³ï¼Œæ˜¯é€ƒé¿ç°å®ã€è¿½æ±‚å®é™çš„æ€æƒ³ã€‚
    """
```


# æ¨¡å‹æ ·ä¾‹å±•ç¤º
æˆ‘ä»¬æ„å»ºäº†å¤šç§åº”ç”¨åœºæ™¯ï¼Œä½¿ç”¨Zhigong-1.6B-Chatæ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ã€‚

## å·¥ä¸šé—®ç­”
```
ç”¨æˆ·ï¼š
ä»€ä¹ˆæ˜¯PLCï¼Ÿ
Zhigong-1.6B-Chatï¼š
PLCï¼ˆProgrammable Logic Controllerï¼‰æ˜¯ä¸€ç§å·¥ä¸šæ§åˆ¶ç³»ç»Ÿï¼Œå®ƒå°†è®¡ç®—æœºä¸å·¥ä¸šæ§åˆ¶ç³»ç»Ÿç›¸ç»“åˆï¼Œå®ç°å¯¹å·¥ä¸šè®¾å¤‡çš„æ§åˆ¶å’Œæ“ä½œã€‚å®ƒé€šè¿‡ç¼–ç¨‹å®ç°å¯¹è®¾å¤‡çš„æ§åˆ¶ï¼Œå®ç°å¯¹è®¾å¤‡çš„æ™ºèƒ½åŒ–æ§åˆ¶ã€‚

ç”¨æˆ·ï¼š
ä»€ä¹ˆæ˜¯å·¥ä¸šè‡ªåŠ¨åŒ–çš„ä¼ ç»Ÿç»„ä»¶ï¼Ÿ
Zhigong-1.6B-Chatï¼š
å·¥ä¸šè‡ªåŠ¨åŒ–ä¼ ç»Ÿç»„ä»¶æ˜¯æŒ‡å·¥ä¸šè‡ªåŠ¨åŒ–ç³»ç»Ÿçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬ä¼ æ„Ÿå™¨ã€æ‰§è¡Œå™¨ã€æ§åˆ¶ç³»ç»Ÿã€è®¡ç®—æœºç­‰ã€‚è¿™äº›ç»„ä»¶é€šå¸¸ç”±å·¥ä¸šåˆ¶é€ å•†æˆ–ç¬¬ä¸‰æ–¹ä¾›åº”å•†æä¾›ï¼Œä»¥ç¡®ä¿å·¥ä¸šè‡ªåŠ¨åŒ–ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚

ç”¨æˆ·ï¼š
ä»€ä¹ˆæ˜¯å·¥ä¸šç‰©è”ç½‘ï¼ˆIIoTï¼‰ï¼Ÿ
Zhigong-1.6B-Chatï¼š
å·¥ä¸šç‰©è”ç½‘ï¼ˆIIoTï¼‰æ˜¯ä¸€ç§å°†å·¥ä¸šè®¾å¤‡ã€ä¼ æ„Ÿå™¨ã€è½¯ä»¶å’Œæ•°æ®ç­‰æŠ€æœ¯è¿æ¥èµ·æ¥çš„ç½‘ç»œï¼Œä»¥å®ç°å·¥ä¸šè®¾å¤‡çš„è¿œç¨‹ç›‘æ§ã€æ•°æ®é‡‡é›†å’Œæ™ºèƒ½æ§åˆ¶ã€‚IIoTå¯ä»¥å¸®åŠ©ä¼ä¸šæé«˜ç”Ÿäº§æ•ˆç‡ã€é™ä½æˆæœ¬ã€æé«˜äº§å“è´¨é‡å’ŒæœåŠ¡æ°´å¹³ï¼Œå¹¶å®ç°è®¾å¤‡çš„æ™ºèƒ½ç»´æŠ¤å’Œæ•…éšœé¢„æµ‹ã€‚

ç”¨æˆ·ï¼š
å·¥ä¸šä¸­çš„èƒ½æºç®¡ç†æ˜¯ä»€ä¹ˆï¼Ÿ
Zhigong-1.6B-Chatï¼š
å·¥ä¸šä¸­çš„èƒ½æºç®¡ç†æ˜¯æŒ‡åœ¨å·¥ä¸šç”Ÿäº§è¿‡ç¨‹ä¸­ï¼Œå¯¹èƒ½æºçš„ä½¿ç”¨ã€ç®¡ç†ã€åˆ†é…å’ŒèŠ‚çº¦ç­‰æ–¹é¢è¿›è¡Œçš„è§„åˆ’ã€è®¾è®¡ã€å®æ–½å’Œç›‘æ§ç­‰ä¸€ç³»åˆ—æ´»åŠ¨ã€‚å®ƒæ¶‰åŠåˆ°ç”Ÿäº§è¿‡ç¨‹ä¸­çš„å„ä¸ªç¯èŠ‚ï¼ŒåŒ…æ‹¬ç”Ÿäº§è®¾å¤‡ã€ç”Ÿäº§å·¥è‰ºã€ç”Ÿäº§ç®¡ç†ã€èƒ½æºç®¡ç†ã€èƒ½æºåˆ©ç”¨æ•ˆç‡ç­‰ã€‚
```


## ç¿»è¯‘
```
ç”¨æˆ·ï¼š
è¯·å°†ä»¥ä¸‹å¥å­ç¿»è¯‘æˆä¸­æ–‡ï¼šãƒãƒ¯ã‚¤ã®weatheræ˜¯veryçš„å¥½ï¼Œìš°ë¦¬ í•¨ê»˜ go shoppingå’Œãƒ”ã‚¯ãƒ‹ãå§ï¼

Zhigong-1.6B-Chatï¼š
å¤å¨å¤·çš„å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘ä»¬ä¸€èµ·å»è´­ç‰©å§ï¼

ç”¨æˆ·ï¼š
"Ğ’ĞµÑ‡ĞµÑ€ Ñ‚Ğ¸Ñ…Ğ¾Ğ¹ Ğ¿ĞµÑĞ½ĞµÑ Ğ½Ğ°Ğ´ Ñ€ĞµĞºĞ¾Ğ¹ Ğ¿Ğ»Ñ‹Ğ²Ñ‘Ñ‚."æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

Zhigong-1.6B-Chatï¼š
â€œæ™šé£è½»æ‹‚ï¼Œåœ¨æ²³æµçš„å¦ä¸€è¾¹ï¼Œæˆ‘å¬åˆ°é‚£è½»å¿«çš„æ­Œå£°ã€‚â€
```

## ä»£ç 
```
ç”¨æˆ·ï¼š
å†™ä¸€æ®µC++ä»£ç  å®Œæˆå†’æ³¡æ’åº

Zhigong-1.6B-Chatï¼š
#include <iostream>
#include <vector>

void bubbleSort(std::vector<int>& arr) {
    for (int i = 0; i < arr.size(); i++) {
        for (int j = 0; j < arr.size() - i - 1; j++) {
            if (arr[j] > arr[j + 1]) {
                std::swap(arr[j], arr[j + 1]);
            }
        }
    }
}

int main() {
    std::vector<int> arr = {10, 7, 8, 9, 1, 5, 6, 4, 3, 2};
    bubbleSort(arr);
    std::cout << "Sorted array: " << std::endl;
    std::cout << arr << std::endl;
    return 0;
}
```

## æ•°å­¦
```
ç”¨æˆ·ï¼š
å¦‚æœ3x+1=10ï¼Œé‚£ä¹ˆxç­‰äºå¤šå°‘ï¼Ÿ

Zhigong-1.6B-Chatï¼š
å¦‚æœ3x+1=10ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†ç­‰å¼ä¸¤è¾¹éƒ½å‡å»1æ¥è§£å‡ºxçš„å€¼ã€‚
3x + 1 - 1 = 10 - 1
3x = 9
ç°åœ¨æˆ‘ä»¬å¯ä»¥è§£å‡ºxçš„å€¼ï¼š
x = 9 / 3
x = 3
æ‰€ä»¥ï¼Œxç­‰äº3

ç”¨æˆ·ï¼š
åºåˆ—1,4,9,16çš„åä¸€ä¸ªæ•°æ˜¯ä»€ä¹ˆï¼Ÿ

Zhigong-1.6B-Chatï¼š
åºåˆ—1,4,9,16çš„åä¸€ä¸ªæ•°æ˜¯25ã€‚
```

## è¯—è¯æ–‡å­¦
```
ç”¨æˆ·ï¼š
â€œä½†æ„¿äººé•¿ä¹…ï¼Œåƒé‡Œå…±å©µå¨Ÿâ€ï¼Œå…¶ä¸­å©µå¨ŸæŒ‡çš„æ˜¯ä»€ä¹ˆï¼Ÿ

Zhigong-1.6B-Chatï¼š
å©µå¨ŸæŒ‡çš„æ˜¯æœˆäº®ã€‚

ç”¨æˆ·ï¼š
â€œä¸æ˜¯ä¸œé£å‹äº†è¥¿é£ï¼Œå°±æ˜¯è¥¿é£å‹äº†ä¸œé£â€ä¸€è¯­å‡ºè‡ªã€Šçº¢æ¥¼æ¢¦ã€‹ä¸­ä½•äººä¹‹å£ï¼Ÿ

Zhigong-1.6B-Chatï¼š
æ—é»›ç‰ã€‚ä¸æ˜¯ä¸œé£å‹äº†è¥¿é£ï¼Œå°±æ˜¯è¥¿é£å‹äº†ä¸œé£ã€‚è¿™å¥å‡ºè‡ªã€Šçº¢æ¥¼æ¢¦ã€‹ä¸­æ—é»›ç‰çš„å£ä¸­ã€‚
```

